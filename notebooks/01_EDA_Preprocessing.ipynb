{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d229e1fc",
   "metadata": {},
   "source": [
    "# 01 — EDA & Preprocessing (Ticker-Agnostic)\n",
    "\n",
    "This notebook:\n",
    "- Reads `TICKER` from environment (no hardcoded tickers)\n",
    "- Downloads OHLCV data via `yfinance`\n",
    "- Writes raw CSV → `data/raw/{TICKER}.csv`\n",
    "- Runs validation + EDA (plots)\n",
    "- Engineers features + time-aware split\n",
    "- Writes processed CSV → `data/processed/{TICKER}.csv`\n",
    "- Writes EDA log JSON → `data/logs/{TICKER}_eda.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9d029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (injected by backend/runner)\n",
    "import os\n",
    "\n",
    "TICKER = os.environ.get(\"TICKER\")\n",
    "if not TICKER:\n",
    "    raise ValueError(\"TICKER env var is required (e.g., set TICKER=AAPL)\")\n",
    "\n",
    "TICKER = TICKER.strip().upper()\n",
    "print(\"TICKER:\", TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c74ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4879614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (repo-root relative)\n",
    "ROOT = Path(\".\").resolve()\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROC_DIR = DATA_DIR / \"processed\"\n",
    "LOG_DIR = DATA_DIR / \"logs\"\n",
    "\n",
    "for d in (RAW_DIR, PROC_DIR, LOG_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "raw_path = RAW_DIR / f\"{TICKER}.csv\"\n",
    "proc_path = PROC_DIR / f\"{TICKER}.csv\"\n",
    "eda_log_path = LOG_DIR / f\"{TICKER}_eda.json\"\n",
    "\n",
    "raw_path, proc_path, eda_log_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972f6334",
   "metadata": {},
   "source": [
    "## 1) Ingestion (yfinance)\n",
    "\n",
    "We keep ingestion deterministic and rerunnable: if raw file exists, we overwrite it from source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c5ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = yf.download(TICKER, period=\"max\", auto_adjust=False, progress=False)\n",
    "if df is None or df.empty:\n",
    "    raise RuntimeError(f\"No data returned for ticker: {TICKER}\")\n",
    "\n",
    "df = df.reset_index().rename(columns={\"Date\": \"date\"})\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], utc=False)\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da126ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw\n",
    "df.to_csv(raw_path, index=False)\n",
    "print(\"Saved raw:\", raw_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896eaa19",
   "metadata": {},
   "source": [
    "## 2) Validation\n",
    "- duplicates\n",
    "- nulls\n",
    "- missing business dates (approx. check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = {}\n",
    "\n",
    "# duplicates by date\n",
    "dup_count = int(df.duplicated(subset=[\"date\"]).sum())\n",
    "val[\"duplicate_dates\"] = dup_count\n",
    "\n",
    "# null counts\n",
    "null_counts = df.isna().sum().to_dict()\n",
    "val[\"null_counts\"] = {k: int(v) for k, v in null_counts.items()}\n",
    "\n",
    "# missing business days (rough; markets have holidays)\n",
    "dmin, dmax = df[\"date\"].min(), df[\"date\"].max()\n",
    "expected = pd.date_range(dmin.normalize(), dmax.normalize(), freq=\"B\")\n",
    "observed = pd.to_datetime(df[\"date\"].dt.normalize().unique())\n",
    "missing = sorted(set(expected) - set(observed))\n",
    "val[\"missing_business_days_count\"] = int(len(missing))\n",
    "val[\"date_range\"] = {\"min\": dmin.isoformat(), \"max\": dmax.isoformat()}\n",
    "\n",
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210bb19c",
   "metadata": {},
   "source": [
    "## 3) EDA\n",
    "- price + volume\n",
    "- returns distribution\n",
    "- rolling mean + volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ce80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_col = \"adj_close\" if \"adj_close\" in df.columns else \"close\"\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(df[\"date\"], df[close_col], label=close_col)\n",
    "ax1.set_title(f\"{TICKER} — Price\")\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"Price\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax2 = plt.subplots()\n",
    "ax2.bar(df[\"date\"], df.get(\"volume\", pd.Series([0]*len(df))), width=1.0)\n",
    "ax2.set_title(f\"{TICKER} — Volume\")\n",
    "ax2.set_xlabel(\"Date\")\n",
    "ax2.set_ylabel(\"Volume\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bac7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = df[[\"date\", close_col]].copy().sort_values(\"date\")\n",
    "ts[\"returns\"] = ts[close_col].pct_change()\n",
    "\n",
    "sns.histplot(ts[\"returns\"].dropna(), bins=100, kde=True)\n",
    "plt.title(f\"{TICKER} — Daily Returns Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 20\n",
    "ts[\"rolling_mean\"] = ts[close_col].rolling(window).mean()\n",
    "ts[\"rolling_vol\"] = ts[\"returns\"].rolling(window).std() * np.sqrt(252)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ts[\"date\"], ts[close_col], label=\"price\", alpha=0.6)\n",
    "ax.plot(ts[\"date\"], ts[\"rolling_mean\"], label=f\"{window}d rolling mean\")\n",
    "ax.set_title(f\"{TICKER} — Rolling Mean\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ts[\"date\"], ts[\"rolling_vol\"], label=f\"{window}d annualized vol\")\n",
    "ax.set_title(f\"{TICKER} — Rolling Volatility\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e703004a",
   "metadata": {},
   "source": [
    "## 4) Log summary stats → `data/logs/{TICKER}_eda.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a995b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"ticker\": TICKER,\n",
    "    \"generated_at_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"rows\": int(len(df)),\n",
    "    \"columns\": list(df.columns),\n",
    "    \"validation\": val,\n",
    "    \"price_summary\": {\n",
    "        \"close_col\": close_col,\n",
    "        \"min\": float(ts[close_col].min()),\n",
    "        \"max\": float(ts[close_col].max()),\n",
    "        \"mean\": float(ts[close_col].mean()),\n",
    "        \"std\": float(ts[close_col].std()),\n",
    "    },\n",
    "    \"returns_summary\": {\n",
    "        \"mean\": float(ts[\"returns\"].mean(skipna=True)),\n",
    "        \"std\": float(ts[\"returns\"].std(skipna=True)),\n",
    "        \"skew\": float(ts[\"returns\"].dropna().skew()),\n",
    "        \"kurt\": float(ts[\"returns\"].dropna().kurt()),\n",
    "    },\n",
    "}\n",
    "\n",
    "eda_log_path.write_text(json.dumps(summary, indent=2))\n",
    "print(\"Saved EDA log:\", eda_log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500cffa0",
   "metadata": {},
   "source": [
    "## 5) Preprocessing + Feature Engineering\n",
    "\n",
    "Features:\n",
    "- returns\n",
    "- rolling averages\n",
    "- rolling volatility\n",
    "\n",
    "Then a time-aware split and save to `data/processed/{TICKER}.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c3370",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = df[[\"date\", close_col] + ([\"volume\"] if \"volume\" in df.columns else [])].copy()\n",
    "proc = proc.sort_values(\"date\").drop_duplicates(subset=[\"date\"]).reset_index(drop=True)\n",
    "\n",
    "# basic cleaning\n",
    "proc[close_col] = proc[close_col].astype(float)\n",
    "if \"volume\" in proc.columns:\n",
    "    proc[\"volume\"] = pd.to_numeric(proc[\"volume\"], errors=\"coerce\")\n",
    "\n",
    "proc = proc.dropna(subset=[\"date\", close_col])\n",
    "\n",
    "# features\n",
    "proc[\"returns\"] = proc[close_col].pct_change()\n",
    "for w in (5, 10, 20):\n",
    "    proc[f\"roll_mean_{w}\"] = proc[close_col].rolling(w).mean()\n",
    "    proc[f\"roll_vol_{w}\"] = proc[\"returns\"].rolling(w).std()\n",
    "\n",
    "# final clean\n",
    "proc = proc.replace([np.inf, -np.inf], np.nan)\n",
    "proc = proc.dropna().reset_index(drop=True)\n",
    "\n",
    "# time-aware split (last 20% for validation)\n",
    "n = len(proc)\n",
    "split_idx = int(n * 0.8)\n",
    "proc[\"split\"] = \"train\"\n",
    "proc.loc[split_idx:, \"split\"] = \"val\"\n",
    "\n",
    "proc.to_csv(proc_path, index=False)\n",
    "print(\"Saved processed:\", proc_path)\n",
    "proc.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
