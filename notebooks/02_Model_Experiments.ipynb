{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb2c8a6",
   "metadata": {},
   "source": [
    "# 02 — Model Experiments & Selection (Ticker-Agnostic)\n",
    "\n",
    "Trains and evaluates:\n",
    "- ARIMA (statsmodels)\n",
    "- Prophet (prophet)\n",
    "- LSTM (tensorflow/keras)\n",
    "\n",
    "Logs metrics → `data/logs/{TICKER}_experiments.json`.\n",
    "\n",
    "Selects best by RMSE, archives existing `models/latest/{TICKER}` → `models/archived/{TICKER}/{timestamp}/`,\n",
    "then saves:\n",
    "- `models/latest/{TICKER}/model.pkl`\n",
    "- `models/latest/{TICKER}/metadata.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe29d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (injected by backend/runner)\n",
    "import os\n",
    "\n",
    "TICKER = os.environ.get(\"TICKER\")\n",
    "if not TICKER:\n",
    "    raise ValueError(\"TICKER env var is required (e.g., set TICKER=AAPL)\")\n",
    "\n",
    "TICKER = TICKER.strip().upper()\n",
    "print(\"TICKER:\", TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path(\".\").resolve()\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "PROC_PATH = DATA_DIR / \"processed\" / f\"{TICKER}.csv\"\n",
    "LOG_DIR = DATA_DIR / \"logs\"\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "EXP_LOG_PATH = LOG_DIR / f\"{TICKER}_experiments.json\"\n",
    "\n",
    "MODELS_DIR = ROOT / \"models\"\n",
    "LATEST_DIR = MODELS_DIR / \"latest\" / TICKER\n",
    "ARCHIVE_BASE = MODELS_DIR / \"archived\" / TICKER\n",
    "\n",
    "for d in (MODELS_DIR, LATEST_DIR, ARCHIVE_BASE):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not PROC_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Processed dataset not found: {PROC_PATH}\")\n",
    "\n",
    "df = pd.read_csv(PROC_PATH, parse_dates=[\"date\"])\n",
    "df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "close_col = \"adj_close\" if \"adj_close\" in df.columns else \"close\"\n",
    "if close_col not in df.columns:\n",
    "    raise ValueError(f\"Expected close column not found in processed data. Found: {list(df.columns)}\")\n",
    "\n",
    "train_df = df[df[\"split\"] == \"train\"].copy()\n",
    "val_df = df[df[\"split\"] == \"val\"].copy()\n",
    "\n",
    "y_train = train_df[close_col].astype(float).values\n",
    "y_val = val_df[close_col].astype(float).values\n",
    "\n",
    "date_min = df[\"date\"].min().date().isoformat()\n",
    "date_max = df[\"date\"].max().date().isoformat()\n",
    "\n",
    "len(train_df), len(val_df), close_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fc628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "\n",
    "def mape(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.maximum(np.abs(y_true), eps)\n",
    "    return float(np.mean(np.abs((y_true - y_pred) / denom)))\n",
    "\n",
    "def safe_json(obj):\n",
    "    # ensure JSON serializable\n",
    "    if isinstance(obj, (np.floating, np.integer)):\n",
    "        return obj.item()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd86d97",
   "metadata": {},
   "source": [
    "## 1) ARIMA (grid over small orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd7f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_result = {\"model\": \"ARIMA\", \"status\": \"skipped\"}\n",
    "try:\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "    best = None\n",
    "    best_fit = None\n",
    "    # small grid (kept light for automation)\n",
    "    for p in [0, 1, 2, 3]:\n",
    "        for d in [0, 1]:\n",
    "            for q in [0, 1, 2]:\n",
    "                try:\n",
    "                    fit = ARIMA(y_train, order=(p, d, q)).fit()\n",
    "                    pred = fit.forecast(steps=len(y_val))\n",
    "                    score = rmse(y_val, pred)\n",
    "                    if best is None or score < best[\"rmse\"]:\n",
    "                        best = {\n",
    "                            \"order\": (p, d, q),\n",
    "                            \"rmse\": score,\n",
    "                            \"mape\": mape(y_val, pred),\n",
    "                        }\n",
    "                        best_fit = fit\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "    if best_fit is None:\n",
    "        raise RuntimeError(\"ARIMA grid search failed for all orders\")\n",
    "\n",
    "    arima_result = {\n",
    "        \"model\": \"ARIMA\",\n",
    "        \"status\": \"ok\",\n",
    "        **best,\n",
    "    }\n",
    "    arima_artifact = {\"type\": \"ARIMA\", \"order\": best[\"order\"], \"fit\": best_fit}\n",
    "except Exception as e:\n",
    "    arima_result = {\"model\": \"ARIMA\", \"status\": \"error\", \"error\": str(e)}\n",
    "    arima_artifact = None\n",
    "\n",
    "arima_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee8f701",
   "metadata": {},
   "source": [
    "## 2) Prophet\n",
    "\n",
    "Requires `prophet` package. If missing, it will be marked as `error` in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dc98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_result = {\"model\": \"Prophet\", \"status\": \"skipped\"}\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "\n",
    "    p_train = train_df[[\"date\", close_col]].rename(columns={\"date\": \"ds\", close_col: \"y\"})\n",
    "    p_val = val_df[[\"date\", close_col]].rename(columns={\"date\": \"ds\", close_col: \"y\"})\n",
    "\n",
    "    m = Prophet(daily_seasonality=False, weekly_seasonality=True, yearly_seasonality=True)\n",
    "    m.fit(p_train)\n",
    "\n",
    "    future = p_val[[\"ds\"]]\n",
    "    forecast = m.predict(future)\n",
    "    pred = forecast[\"yhat\"].values\n",
    "\n",
    "    prophet_result = {\n",
    "        \"model\": \"Prophet\",\n",
    "        \"status\": \"ok\",\n",
    "        \"rmse\": rmse(p_val[\"y\"].values, pred),\n",
    "        \"mape\": mape(p_val[\"y\"].values, pred),\n",
    "    }\n",
    "    prophet_artifact = {\"type\": \"Prophet\", \"model\": m}\n",
    "except Exception as e:\n",
    "    prophet_result = {\"model\": \"Prophet\", \"status\": \"error\", \"error\": str(e)}\n",
    "    prophet_artifact = None\n",
    "\n",
    "prophet_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ebd42",
   "metadata": {},
   "source": [
    "## 3) LSTM (simple)\n",
    "\n",
    "Creates supervised windows on close price, trains a small LSTM, and forecasts the validation horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_result = {\"model\": \"LSTM\", \"status\": \"skipped\"}\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "\n",
    "    # normalize using train stats\n",
    "    mu = float(np.mean(y_train))\n",
    "    sigma = float(np.std(y_train) + 1e-8)\n",
    "    y_train_s = (y_train - mu) / sigma\n",
    "    y_val_s = (y_val - mu) / sigma\n",
    "\n",
    "    def make_windows(series, window):\n",
    "        X, Y = [], []\n",
    "        for i in range(len(series) - window):\n",
    "            X.append(series[i:i+window])\n",
    "            Y.append(series[i+window])\n",
    "        X = np.asarray(X, dtype=np.float32)[..., None]\n",
    "        Y = np.asarray(Y, dtype=np.float32)\n",
    "        return X, Y\n",
    "\n",
    "    window = 30\n",
    "    Xtr, Ytr = make_windows(y_train_s, window)\n",
    "    # train small, deterministic-ish\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(window, 1)),\n",
    "        keras.layers.LSTM(32),\n",
    "        keras.layers.Dense(1),\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mse\")\n",
    "    model.fit(Xtr, Ytr, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    # recursive forecast over validation horizon\n",
    "    history = list(y_train_s[-window:])\n",
    "    preds_s = []\n",
    "    for _ in range(len(y_val_s)):\n",
    "        x = np.asarray(history[-window:], dtype=np.float32)[None, :, None]\n",
    "        yhat = float(model.predict(x, verbose=0).ravel()[0])\n",
    "        preds_s.append(yhat)\n",
    "        history.append(yhat)\n",
    "\n",
    "    preds = np.asarray(preds_s) * sigma + mu\n",
    "\n",
    "    lstm_result = {\n",
    "        \"model\": \"LSTM\",\n",
    "        \"status\": \"ok\",\n",
    "        \"rmse\": rmse(y_val, preds),\n",
    "        \"mape\": mape(y_val, preds),\n",
    "        \"window\": window,\n",
    "        \"epochs\": 10,\n",
    "    }\n",
    "\n",
    "    # store picklable bundle\n",
    "    lstm_artifact = {\n",
    "        \"type\": \"LSTM\",\n",
    "        \"model_json\": model.to_json(),\n",
    "        \"weights\": model.get_weights(),\n",
    "        \"mu\": mu,\n",
    "        \"sigma\": sigma,\n",
    "        \"window\": window,\n",
    "    }\n",
    "except Exception as e:\n",
    "    lstm_result = {\"model\": \"LSTM\", \"status\": \"error\", \"error\": str(e)}\n",
    "    lstm_artifact = None\n",
    "\n",
    "lstm_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e55cf9c",
   "metadata": {},
   "source": [
    "## 4) Log experiments + Select best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cb9dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [arima_result, prophet_result, lstm_result]\n",
    "\n",
    "ok = [r for r in results if r.get(\"status\") == \"ok\"]\n",
    "if not ok:\n",
    "    raise RuntimeError(f\"No models trained successfully: {results}\")\n",
    "\n",
    "best = sorted(ok, key=lambda r: r[\"rmse\"])[0]\n",
    "best_type = best[\"model\"]\n",
    "\n",
    "experiment_log = {\n",
    "    \"ticker\": TICKER,\n",
    "    \"generated_at_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"data_range\": {\"min\": date_min, \"max\": date_max},\n",
    "    \"n_train\": int(len(train_df)),\n",
    "    \"n_val\": int(len(val_df)),\n",
    "    \"target\": close_col,\n",
    "    \"results\": results,\n",
    "    \"best\": best,\n",
    "}\n",
    "\n",
    "EXP_LOG_PATH.write_text(json.dumps(experiment_log, indent=2, default=safe_json))\n",
    "print(\"Saved experiments log:\", EXP_LOG_PATH)\n",
    "print(\"Best:\", best_type, \"RMSE:\", best[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02d282d",
   "metadata": {},
   "source": [
    "## 5) Archive previous model + Save new best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ef596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def archive_latest_if_exists(latest_dir: Path, archive_base: Path):\n",
    "    if latest_dir.exists() and any(latest_dir.iterdir()):\n",
    "        ts = datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "        dest = archive_base / ts\n",
    "        dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if dest.exists():\n",
    "            shutil.rmtree(dest)\n",
    "        shutil.move(str(latest_dir), str(dest))\n",
    "        latest_dir.mkdir(parents=True, exist_ok=True)\n",
    "        return str(dest)\n",
    "    latest_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return None\n",
    "\n",
    "archived_to = archive_latest_if_exists(LATEST_DIR, ARCHIVE_BASE)\n",
    "print(\"Archived to:\", archived_to)\n",
    "\n",
    "artifact = None\n",
    "if best_type == \"ARIMA\":\n",
    "    artifact = arima_artifact\n",
    "elif best_type == \"Prophet\":\n",
    "    artifact = prophet_artifact\n",
    "elif best_type == \"LSTM\":\n",
    "    artifact = lstm_artifact\n",
    "else:\n",
    "    raise ValueError(f\"Unknown best model type: {best_type}\")\n",
    "\n",
    "model_pkl = LATEST_DIR / \"model.pkl\"\n",
    "meta_json = LATEST_DIR / \"metadata.json\"\n",
    "\n",
    "with model_pkl.open(\"wb\") as f:\n",
    "    pickle.dump(artifact, f)\n",
    "\n",
    "metadata = {\n",
    "    \"ticker\": TICKER,\n",
    "    \"model_type\": best_type,\n",
    "    \"trained_at_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"metrics\": {\"rmse\": best[\"rmse\"], \"mape\": best[\"mape\"]},\n",
    "    \"data_range\": {\"min\": date_min, \"max\": date_max},\n",
    "    \"target\": close_col,\n",
    "    \"archived_previous_to\": archived_to,\n",
    "}\n",
    "\n",
    "meta_json.write_text(json.dumps(metadata, indent=2, default=safe_json))\n",
    "\n",
    "print(\"Saved:\", model_pkl)\n",
    "print(\"Saved:\", meta_json)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
